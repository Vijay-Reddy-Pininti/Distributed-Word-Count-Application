{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d11c18-22a0-4495-ba08-47566910a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import re\n",
    "import string\n",
    "from pyspark.sql import SparkSession\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5491ce8f-c274-423c-977b-515bf3db893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCount(input, output, num_common_words, stop_words):\n",
    "    # Start Spark Session\n",
    "    spark = SparkSession.builder.master(\"local\").appName(\"ExtendedWordCount\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "\n",
    "    # Read all input files from directory\n",
    "    text = sc.wholeTextFiles(input).values()\n",
    "\n",
    "    # Convert text to words in lower case\n",
    "    words = text.flatMap(lambda x: x.lower().split())\n",
    "\n",
    "    # Replace punctuations that are not part of the word and map them a count\n",
    "    words = words.map(lambda x: (x.lstrip(string.punctuation)).rstrip(string.punctuation))\n",
    "\n",
    "    # Filter stop words\n",
    "    non_stop_words = words.filter(lambda x: x not in stop_words)\n",
    "\n",
    "    # Give Count of individual words\n",
    "    maps = non_stop_words.map(lambda x: (x, 1))\n",
    "\n",
    "    # Count of all words\n",
    "    counts = maps.reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "    # Get the commmon 25 words\n",
    "    common = counts.takeOrdered(num_common_words, key = lambda x: -x[1])\n",
    "    \n",
    "    # Save the counts to a file\n",
    "    sc.parallelize(common).saveAsTextFile(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4461c7f-2e91-44ae-81a1-d1e0db582c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to input and output files\n",
    "input = \"./input\"\n",
    "output = \"./extended-output\"\n",
    "\n",
    "# Number of common words\n",
    "num_common_words = 25\n",
    "\n",
    "# Define stop words\n",
    "stop_words = [\"the\", \"and\", \"is\", \"in\", \"it\", \"or\", \"of\", \"to\", 'a', 'that', 'was', 'you', 'his', 'had', 'with', 'him', 'for', 'as', 'at', 'not', 'be', 'on', 'my', 'her', 'are', 'he', 'have', 'me', 'by', 'from', 'but', 'would', 'were', 'what', 'an', 'so', 'this', 'been', 'she', 'will', 'about', 'there', 'am', 'your', 'who', 'here', 'they', 'do', 'which', 'if', 'them', 'when', 'into', 'has', 'can']\n",
    "\n",
    "# Invoking Word Count function\n",
    "wordCount(input, output, num_common_words, stop_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
